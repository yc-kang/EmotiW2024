{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19bd3e6-1fe4-4e8b-bb62-37b3b304074f",
   "metadata": {},
   "source": [
    "Note: This is for quad modalities combination\n",
    "\n",
    "### Train Fusion\n",
    "Data:\n",
    "- `config.FUSION_QUAD`: Openface + Marlin + Mediapipe + Videollava"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0400602-1f9d-4caa-b93c-dfe3eddf5f29",
   "metadata": {},
   "source": [
    "### Model Details\n",
    "Details:\n",
    "- It uses combined dataset (openface+marlin+mediapipe+videollava) for higher accuracy\n",
    "- It uses `data_loader_quad` in `data_prep.py`\n",
    "- Make sure `npy` data file is preprocessed, before model training\n",
    "- It uses `transformer_fusion` model for ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a72743d-8a54-4887-a372-e022380d1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "from keras.layers import Flatten, Concatenate, LSTM, Dense, Conv2D, Conv3D, GlobalAveragePooling1D, Dropout, MaxPooling2D\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from data_prep import data_loader_v1, data_loader_fusion, data_loader_triple, data_loader_quad\n",
    "import config\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a41d2f-323d-4936-9335-b24f12284157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "        self.mask_layer = MaskComputationLayer()  # Use the new mask layer\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return self.mask_layer(inputs)  # Use the mask layer to compute mask\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"output_dim\": self.output_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class MaskComputationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), \n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79707b9-b594-47de-8f51-cd369ed62b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_model(x, input_shape, num_heads, mlp_units, mlp_dropout):\n",
    "    dense_dim = 8\n",
    "    embed_dim = input_shape[1]\n",
    "    \n",
    "    x = PositionalEmbedding(\n",
    "        input_shape[0], embed_dim, name=\"frame_position_embedding_usr\"\n",
    "    )(x)\n",
    "    \n",
    "    \n",
    "#     x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "    x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "    \n",
    "#     # late fusin\n",
    "#     for dim in mlp_units:\n",
    "#         x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "#         x = layers.Dropout(mlp_dropout)(x)\n",
    "        \n",
    "#     x = layers.Dense(4, activation='softmax')(x)\n",
    "    return x\n",
    "\n",
    "def build_stm_model(x, input_shape, num_heads, mlp_units, mlp_dropout):\n",
    "    dense_dim = 8\n",
    "    embed_dim = input_shape[1]\n",
    "    \n",
    "    x = PositionalEmbedding(\n",
    "        input_shape[0], embed_dim, name=\"frame_position_embedding_stm\"\n",
    "    )(x)\n",
    "    \n",
    "  \n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "    x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "    \n",
    "#     # late fusing\n",
    "#     for dim in mlp_units:\n",
    "#         x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "#         x = layers.Dropout(mlp_dropout)(x)\n",
    "        \n",
    "#     x = layers.Dense(4, activation='softmax')(x)\n",
    "    return x\n",
    "\n",
    "# def transformer_enc(\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim=4, dropout=0.3):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "    \n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7af09d7-3945-4ab7-bc16-42a58513eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        input_shape_1,\n",
    "        input_shape_2,\n",
    "        input_shape_3,\n",
    "        input_shape_4,\n",
    "        head_size,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_transformer_blocks,\n",
    "        mlp_units,\n",
    "        dropout=0,\n",
    "        mlp_dropout=0,\n",
    "        n_classes=4\n",
    "    ):\n",
    "    inputs_1 = keras.Input(shape=input_shape_1)\n",
    "    inputs_2 = keras.Input(shape=input_shape_2)\n",
    "    inputs_3 = keras.Input(shape=input_shape_3)\n",
    "    inputs_4 = keras.Input(shape=input_shape_4)\n",
    "    dense_dim = 8\n",
    "    \n",
    "    stream1_x = build_user_model(inputs_1, input_shape_1, num_heads, mlp_units, mlp_dropout)\n",
    "    stream2_x = build_stm_model(inputs_2, input_shape_2, num_heads, mlp_units, mlp_dropout)\n",
    "    stream3_x = build_user_model(inputs_3, input_shape_3, num_heads, mlp_units, mlp_dropout)\n",
    "    steaam4_x = build_stm_model(inputs_4, input_shape_4, num_heads, mlp_units, mlp_dropout)\n",
    "    \n",
    "    x = keras.layers.concatenate([stream1_x, stream2_x, stream3_x, stream4_x])\n",
    "    \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "        \n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    model = keras.Model([inputs_1, inputs_2, inputs_3, inputs_4], outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e503163-d197-46f2-b8d9-6f32c40e666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100000\n",
    "\n",
    "def make_ds(features, labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
    "    ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
    "    return ds\n",
    "\n",
    "def get_best_weights():\n",
    "    import os\n",
    "    def get_epoch(x):\n",
    "        return int(x.split('epoch')[-1].split('-')[0])\n",
    "    return sorted(os.listdir('./checkpoints/'), key=get_epoch)[-1]\n",
    "\n",
    "def train(model_name, val=True):\n",
    "\n",
    "    data = data_loader_quad(model_name, val)\n",
    "\n",
    "    if len(data) == 3:\n",
    "        train, val, test = data\n",
    "        val_x, val_y = val\n",
    "        val_x1, val_x2, val_x3, val_x4 = val_x\n",
    "    else:\n",
    "        train, test = data\n",
    "        \n",
    "    train_x, train_y = train\n",
    "    train_x1, train_x2, train_x3, train_x4 = train_x\n",
    "    \n",
    "    test_x, test_y = test\n",
    "    test_x1, test_x2, test_x3, test_x4 = test_x\n",
    "    \n",
    "    total = train_y.shape[0]\n",
    "    \n",
    "    print (\"train stats: \")\n",
    "    print (train_x1.shape, train_y.shape)\n",
    "    print (train_x2.shape, train_y.shape)\n",
    "    print (train_x3.shape, train_y.shape)\n",
    "    print (train_x4.shape, train_y.shape)\n",
    "    \n",
    "    if val:\n",
    "        print (\"val stats: \")\n",
    "        print (val_x1.shape, val_y.shape)\n",
    "        print (val_x2.shape, val_y.shape)\n",
    "        print (val_x3.shape, val_y.shape)\n",
    "        print (val_x4.shape, val_y.shape)\n",
    "    \n",
    "    print (\"test stats: \")\n",
    "    print (test_x1.shape, test_y.shape)\n",
    "    print (test_x2.shape, test_y.shape)\n",
    "    print (test_x3.shape, test_y.shape)\n",
    "    print (test_x4.shape, test_y.shape)\n",
    "    \n",
    "    # class weight strategy\n",
    "    class_weight = {\n",
    "        k: (1 / train_y[train_y==k].shape[0]) * (total / 4) for k in np.unique(train_y)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    input_shape_1 = train_x1.shape[1:]\n",
    "    input_shape_2 = train_x2.shape[1:]\n",
    "    input_shape_3 = train_x3.shape[1:]\n",
    "    input_shape_4 = train_x4.shape[1:]\n",
    "        \n",
    "    model = build_model(\n",
    "        input_shape_1,\n",
    "        input_shape_2,\n",
    "        input_shape_3,\n",
    "        input_shape_4,\n",
    "        head_size=256,\n",
    "        num_heads=8,\n",
    "        ff_dim=4,\n",
    "        num_transformer_blocks=4,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.5,\n",
    "        dropout=0.3,\n",
    "        n_classes=4\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    filepath = \"checkpoints/\" + model_name + \".epoch{epoch:02d}-acc{val_accuracy:.2f}.keras\"\n",
    "    checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "    \n",
    "    callbacks = [\n",
    "                 keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True),\n",
    "                 checkpoint\n",
    "    ]\n",
    "    if not val:\n",
    "        val_x1 = test_x1\n",
    "        val_x2 = test_x2\n",
    "        val_x3 = test_x3\n",
    "        val_x4 = test_x4\n",
    "        val_y = test_y\n",
    "    model.fit([train_x1, train_x2, train_x3, train_x4], \n",
    "               train_y, \n",
    "               validation_data=([val_x1, val_x2, val_x3, val_x4], val_y), \n",
    "               epochs=200, \n",
    "               callbacks=callbacks,\n",
    "              )\n",
    "    \n",
    "    model.load_weights(f'checkpoints/{get_best_weights()}')\n",
    "    print (\"Evaluating on train set: \")\n",
    "    model.evaluate([train_x1, train_x2, train_x3, train_x4], train_y)\n",
    "\n",
    "    print (\"Evaluating on valid set: \")\n",
    "    model.evaluate([val_x1, val_x2, val_x3, val_x4], val_y)\n",
    "\n",
    "    print (\"Evaluating on test set: \")\n",
    "    model.evaluate([test_x1, test_x2, test_x3, test_x4], test_y)\n",
    "\n",
    "    y_pred_val = np.argmax(model.predict(val_x), axis=1)\n",
    "    y_pred_test = np.argmax(model.predict(test_x), axis=1)\n",
    "\n",
    "    print (\"Classification report (val): \")\n",
    "    print(classification_report(val_y, y_pred_val))\n",
    "   \n",
    "    print (\"Classification report (test): \")\n",
    "    print(classification_report(test_y, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1601b9-ba19-416b-881c-eb57b21bbfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                chunk           label\n",
      "0   subject_68_0ng3yqwrg6_vid_0_0.mp4         Engaged\n",
      "1   subject_68_0ng3yqwrg6_vid_0_1.mp4  Highly-Engaged\n",
      "2  subject_68_0ng3yqwrg6_vid_0_10.mp4  Highly-Engaged\n",
      "3  subject_68_0ng3yqwrg6_vid_0_11.mp4  Highly-Engaged\n",
      "4  subject_68_0ng3yqwrg6_vid_0_12.mp4         Engaged\n",
      "<class 'numpy.ndarray'> 7768\n",
      "TrainXy: ['subject_68_0ng3yqwrg6_vid_0_0.mp4', 'subject_68_0ng3yqwrg6_vid_0_1.mp4', 'subject_68_0ng3yqwrg6_vid_0_10.mp4', 'subject_68_0ng3yqwrg6_vid_0_11.mp4', 'subject_68_0ng3yqwrg6_vid_0_12.mp4']\n",
      "len TrainXy: 5752\n",
      "TestXy: ['subject_96_dh18u00dyu_vid_0_0.mp4', 'subject_96_dh18u00dyu_vid_0_1.mp4', 'subject_96_dh18u00dyu_vid_0_10.mp4', 'subject_96_dh18u00dyu_vid_0_11.mp4', 'subject_96_dh18u00dyu_vid_0_12.mp4']\n",
      "len TestXy: 1698\n",
      "ValXy: ['subject_85_rda0o4n8zs_vid_0_0.mp4', 'subject_85_rda0o4n8zs_vid_0_1.mp4', 'subject_85_rda0o4n8zs_vid_0_10.mp4', 'subject_85_rda0o4n8zs_vid_0_11.mp4', 'subject_85_rda0o4n8zs_vid_0_12.mp4']\n",
      "len ValXy: 892\n",
      "not found(train):  'subject_2_thw33jke4j_vid_1_27.mp4'\n",
      "not found(train):  'subject_39_n3400nou4m_vid_1_1.mp4'\n",
      "not found(train):  'subject_7_as2uk9lhe2_vid_1_7.mp4'\n",
      "not found(train):  'subject_7_as2uk9lhe2_vid_1_7.mp4'\n",
      "not found(train):  'subject_22_37kn4gou0j_vid_0_21.mp4'\n",
      "not found(train):  'subject_22_37kn4gou0j_vid_1_24.mp4'\n",
      "not found(train):  'subject_22_37kn4gou0j_vid_2_20.mp4'\n",
      "not found(train):  'subject_22_37kn4gou0j_vid_2_21.mp4'\n",
      "not found(train):  'subject_22_37kn4gou0j_vid_2_22.mp4'\n",
      "not found(train):  'subject_91_4ah09es9bz_vid_1_19.mp4'\n",
      "not found(train):  'subject_91_4ah09es9bz_vid_1_20.mp4'\n",
      "not found(train):  'subject_57_randomncga496ccj_vid_0_12.mp4'\n",
      "not found(train):  'subject_57_randomncga496ccj_vid_2_11.mp4'\n",
      "not found(train):  'subject_0_2msdhgqawh_vid_2_34.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_12.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_13.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_14.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_15.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_17.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_18.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_21.mp4'\n",
      "not found(train):  'subject_37_random6k0syo0a0y_vid_1_25.mp4'\n",
      "not found(train):  'subject_89_v9k50k1urg_vid_1_24.mp4'\n",
      "not found(train):  'subject_89_v9k50k1urg_vid_1_28.mp4'\n",
      "not found(train):  'subject_89_v9k50k1urg_vid_1_29.mp4'\n",
      "not found(train):  'subject_89_v9k50k1urg_vid_1_30.mp4'\n",
      "not found(train):  'subject_17_ddvyjnjfad_vid_0_5.mp4'\n",
      "not found(train):  'subject_58_88yeke86uv_vid_2_24.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_15.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_17.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_18.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_19.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_20.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_34.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_35.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_36.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_39.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_40.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_44.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_45.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_46.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_48.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_49.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_1_7.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_1.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_10.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_102.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_104.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_105.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_106.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_107.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_11.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_12.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_13.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_14.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_15.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_16.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_17.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_18.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_19.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_20.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_21.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_22.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_23.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_24.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_25.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_26.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_27.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_28.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_29.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_30.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_31.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_32.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_33.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_34.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_35.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_36.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_37.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_38.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_39.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_4.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_40.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_41.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_42.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_43.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_44.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_45.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_46.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_47.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_48.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_49.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_5.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_50.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_51.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_52.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_53.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_54.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_55.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_56.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_57.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_58.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_59.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_6.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_60.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_61.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_62.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_63.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_64.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_65.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_66.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_67.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_68.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_69.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_7.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_70.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_71.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_72.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_73.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_74.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_75.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_76.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_8.mp4'\n",
      "not found(train):  'subject_104_06lc4xlb48_vid_2_9.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_11.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_12.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_15.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_16.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_17.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_18.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_19.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_0_2.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_10.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_11.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_16.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_17.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_19.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_20.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_21.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_23.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_29.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_1_34.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_1.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_11.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_12.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_13.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_14.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_15.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_16.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_17.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_18.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_19.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_2.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_20.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_21.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_22.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_23.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_24.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_25.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_26.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_27.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_28.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_29.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_3.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_31.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_32.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_34.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_5.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_6.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_7.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_8.mp4'\n",
      "not found(train):  'subject_69_randomagje1dcmk3_vid_2_9.mp4'\n",
      "not found(train):  'subject_114_randombn205mtt5s_vid_0_0.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_1.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_10.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_11.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_12.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_13.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_14.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_15.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_16.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_17.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_18.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_2.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_21.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_22.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_23.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_24.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_25.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_26.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_27.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_29.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_31.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_5.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_6.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_7.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_8.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_0_9.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_0.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_1.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_10.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_11.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_12.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_14.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_15.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_16.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_17.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_18.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_19.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_2.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_20.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_21.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_22.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_23.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_24.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_25.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_26.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_27.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_28.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_29.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_3.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_30.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_32.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_33.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_35.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_36.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_37.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_38.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_39.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_4.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_41.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_42.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_43.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_5.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_6.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_7.mp4'\n",
      "not found(train):  'subject_30_7ytx2foxy2_vid_1_9.mp4'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m shutil\u001b[38;5;241m.\u001b[39mrmtree(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFUSION_TRI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model_name, val)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model_name, val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 16\u001b[0m     data\u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader_triple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     19\u001b[0m         train, val, test \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\Documents\\Jupyter\\EmotiW2023\\data_prep.py:97\u001b[0m, in \u001b[0;36mdata_loader_triple\u001b[1;34m(feature_type, val, base_dir)\u001b[0m\n\u001b[0;32m     91\u001b[0m         train_not_found_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;66;03m# pass\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Need to implement some sort of data scaling (But not sure if it's openface or marlin)\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Important!!!\u001b[39;00m\n\u001b[0;32m     96\u001b[0m  \u001b[38;5;66;03m# Pad sequences and scale\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m original_shapes \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m train_x_3]  \u001b[38;5;66;03m# Store original lengths\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Reshape for scaling\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Jupyter\\EmotiW2023\\data_prep.py:36\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, max_length)\u001b[0m\n\u001b[0;32m     34\u001b[0m         padding_length \u001b[38;5;241m=\u001b[39m max_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seq)\n\u001b[0;32m     35\u001b[0m         pad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((padding_length, feature_dim))\n\u001b[1;32m---> 36\u001b[0m         padded_seq \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     padded_sequences\u001b[38;5;241m.\u001b[39mappend(padded_seq)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(padded_sequences)\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\numpy\\core\\shape_base.py:286\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_vhstack_dispatcher)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvstack\u001b[39m(tup, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    Stack arrays in sequence vertically (row wise).\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m \u001b[43matleast_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m         arrs \u001b[38;5;241m=\u001b[39m [arrs]\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\numpy\\core\\shape_base.py:121\u001b[0m, in \u001b[0;36matleast_2d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m    119\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m--> 121\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    123\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "import shutil, os\n",
    "if __name__ == '__main__':\n",
    "    shutil.rmtree('checkpoints/')\n",
    "    os.mkdir('checkpoints')\n",
    "    train(config.FUSION_QUAD, val=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3411b9-67a9-4094-98aa-8f0cf23c6d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
