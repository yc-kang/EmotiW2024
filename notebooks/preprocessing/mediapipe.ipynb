{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8800a0e-c185-4114-8873-a1d96a199760",
   "metadata": {},
   "source": [
    "### Mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0863d60-d5f9-4d12-a5b0-1ff384cf031d",
   "metadata": {},
   "source": [
    "### Input and Output\n",
    "Input files:\n",
    "- Mediapipe `csv` files folder\n",
    "- Label `xlsx` file\n",
    "\n",
    "Output files:\n",
    "- save the processed file in `npy` format:\n",
    "  - `bodypose.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e27e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_segments = 20\n",
    "\n",
    "feature_files = glob.glob(\"lEmotiW2023 Data Small/mediapipe/*.csv\")\n",
    "labels = pd.read_excel('EmotiW2023 Data Small/engagement_labels.xlsx')\n",
    "file_path_dir = 'EmotiW2023 Data Small/mediapipe/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b900eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bodypose(row):\n",
    "    for i in range(33):\n",
    "        if row[f'visibility{i}'] < 0.9:\n",
    "            row[f'x{i}'] = 0\n",
    "            row[f'y{i}'] = 0\n",
    "            row[f'z{i}'] = 0\n",
    "    return row\n",
    "\n",
    "def get_features(input_segment):\n",
    "    if len(input_segment) == 0:\n",
    "        return []\n",
    "    return input_segment.var()\n",
    "\n",
    "def path_to_csv(fname):\n",
    "    return fname.split('.mp4')[0] + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f86de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['frame'] + [f'visibility{i}' for i in range(33)]\n",
    "n_segments = 20\n",
    "\n",
    "def parse_features(file_path):\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.apply(filter_bodypose, axis=1)\n",
    "\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    window_size = int(df.shape[0]/n_segments)\n",
    "    \n",
    "    if window_size < 1:\n",
    "        return []\n",
    "    instance_features = []\n",
    "    start_index = 0\n",
    "    for i in range(n_segments):\n",
    "        if i == n_segments - 1:\n",
    "            end_index = df.shape[0]\n",
    "        else:\n",
    "            end_index = start_index + window_size\n",
    "        \n",
    "        # update here for our dataset\n",
    "#         print (start_index, end_index)\n",
    "        index_features = get_features(df.iloc[start_index:end_index, :])\n",
    "        if len(index_features):\n",
    "            instance_features.append(index_features)\n",
    "        start_index = start_index + window_size\n",
    "    \n",
    "    \n",
    "    instance_features = np.vstack(instance_features)\n",
    "    assert instance_features.shape[0] == 20, \"shape issue\"\n",
    "\n",
    "    return instance_features\n",
    "\n",
    "_errors_ = []\n",
    "def extract_bodypose_features():\n",
    "    data = []\n",
    "    for f in tqdm(labels.to_dict(orient='records')):\n",
    "        \n",
    "        try:\n",
    "            #fname = file_path_dir + path_to_csv(f['chunk'].split('/')[-1])\n",
    "            #features = parse_features(fname)\n",
    "            fname = path_to_csv(f['chunk'])\n",
    "            fname = file_path_dir + fname.split('/')[-1]\n",
    "            features = parse_features(fname)\n",
    "            data.append((fname, \n",
    "                         features, \n",
    "                         f['label']\n",
    "                        ))\n",
    "        except FileNotFoundError:\n",
    "            _errors_.append(fname)\n",
    "        except Exception as e:\n",
    "            print (\"exception: \", e)\n",
    "            _errors_.append(fname)\n",
    "            \n",
    "    return np.array(data, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9acb6c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8040/8040 [1:13:27<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# extract features by feature type\n",
    "Xy = extract_bodypose_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eb2771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EmotiW2023 Data Small/mediapipe/subject_68_0ng3yqwrg6_vid_0_0.csv',\n",
       "       array([[1.12808827e-04, 1.35073279e-04, 2.33070443e-02, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [8.37831144e-07, 5.83291142e-05, 3.40727347e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [9.97596998e-06, 4.23564044e-05, 5.18335506e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              ...,\n",
       "              [1.02391571e-07, 1.85546987e-06, 5.48816644e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [1.06349875e-07, 1.94433832e-07, 1.85562008e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [4.73229441e-07, 1.29487322e-06, 6.26760635e-04, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])   ,\n",
       "       'Engaged'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6526393",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('EmotiW2023 Data Small/Xy_engage_bodypose.npy', Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbcaf156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_mp4(fname):\n",
    "    return fname.split('.csv')[0] + '.mp4'\n",
    "\n",
    "# s = df.drop(drop_cols, axis=1).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa9b0d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_pdm = np.load('EmotiW2023 Data Small/Xy_engage_bodypose.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1be01be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['subject_68_0ng3yqwrg6_vid_0_0.mp4',\n",
       "       array([[1.12808827e-04, 1.35073279e-04, 2.33070443e-02, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [8.37831144e-07, 5.83291142e-05, 3.40727347e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [9.97596998e-06, 4.23564044e-05, 5.18335506e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              ...,\n",
       "              [1.02391571e-07, 1.85546987e-06, 5.48816644e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [1.06349875e-07, 1.94433832e-07, 1.85562008e-03, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "              [4.73229441e-07, 1.29487322e-06, 6.26760635e-04, ...,\n",
       "               0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])   ,\n",
       "       'Engaged'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(Xy_pdm)):\n",
    "    #Xy_pdm[i][0] = 'chunks/' + path_to_mp4(Xy_pdm[i][0].split('/')[-1])\n",
    "    Xy_pdm[i][0] = path_to_mp4(Xy_pdm[i][0].split('/')[-1])\n",
    "\n",
    "Xy_pdm[0]\n",
    "# Make sure it is array(['subject_68_0ng3yqwrg6_vid_0_0.mp4', array([[1.12808827e-04, 1.35073279e-04, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d13efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('EmotiW2023 Data Small/Xy_engage_bodypose.npy', Xy_pdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25275575-8fa0-4723-ad21-1a07874bc89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
