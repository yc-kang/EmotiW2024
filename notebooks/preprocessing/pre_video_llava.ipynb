{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8e9b2d-5638-444b-9353-69b51f29d0e0",
   "metadata": {},
   "source": [
    "### Video-LLaVa preprocessing\n",
    "\n",
    "Run via replicate API [[Example code](https://replicate.com/nateraw/video-llava/examples)]\n",
    "\n",
    "Runtime Experiments:\n",
    "- Current implementation, takes 10 mins per video\n",
    "- Run directly in replicate playground, takes 3 mins per video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8b934-c4e8-4370-8d7a-eacdaf84a242",
   "metadata": {},
   "source": [
    "### Experiment 1 (19 Nov)\n",
    "Prompt:\n",
    "- Only analyze the attention and engagement of the subject, provide 10 relevant keywords, seperation by ','\n",
    "\n",
    "Output Results (Sample):\n",
    "- Not-Engaged: Attention, engagement, headphones, music, focus, concentration, listening, relaxation, comfort, personal space, self-expression.\n",
    "- Barely-Engaged: Attention, engagement, glasses, white wall, white shirt, white background, white room, white surface, white background, white wall, white room.\n",
    "- Engaged: Attention, engagement, headphones, white, black, green, blue, white shirt, black shirt, white jacket, black jacket, white headband, black headband.\n",
    "- Highly-Engaged: Attention, engagement, headphones, woman, white, black, gray, blue, green, yellow, red, white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "876b436a-197c-471b-ba5d-4384fe0c0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "import os\n",
    "\n",
    "# Don't leak the API token\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"\" # replicate profile API token\n",
    "\n",
    "# Video path\n",
    "video = open(\"EmotiW2023 Data/Train/subject_2_thw33jke4j_vid_1_13.mp4\", \"rb\") \n",
    "\n",
    "# Text prompt\n",
    "text_prompt_string = \"\"\"\n",
    "Answer the following questions, based on the video:\n",
    "1. Attention: How often does the participant maintain eye contact with the screen? (Select one: Never, Rarely, Sometimes, Always)\n",
    "\n",
    "2. Distractions: How often does the participant get distracted by external factors (e.g., phone, surroundings)? (Select one: Always, Often, Sometimes, Never)\n",
    "\n",
    "3. Facial Expressions: How often does the participant show facial expressions that indicate understanding or confusion? (Select one: Never, Rarely, Sometimes, Always)\n",
    "\n",
    "4. Eye Movement: How often does the participant's eye movement indicate engagement (e.g., following along with the content, focused on the screen)? (Select one: Never, Rarely, Sometimes, Always)\n",
    "\n",
    "5. Body Language: How often does the participant exhibit positive body language (e.g., nodding, leaning forward)? (Select one: Never, Rarely, Sometimes, Always)\n",
    "\n",
    "6. Consistency: How consistent is the participant's engagement throughout the session? (Select one: Very inconsistent, Inconsistent, Consistent, Very consistent)\n",
    "\n",
    "7. Head Movement: How often does the participant move their head? (Select one: Never, Rarely, Sometimes, Always)\n",
    "\n",
    "8. Body Movement: How often does the participant exhibit body movements? (Select one: Never, Rarely, Sometimes, Always)\n",
    "\n",
    "9. Signs of Boredom: How often does the participant display signs of boredom (e.g., yawning, looking away, fidgeting)? (Select one: Never, Rarely, Sometimes, Always)\n",
    "\n",
    "10. Head Position: How often is the participant's head position upright versus tilted? (Select one: Always upright, Mostly upright, Sometimes tilted, Often tilted)\n",
    "\"\"\"\n",
    "# text_prompt_string = \"Only analyze the attention and engagement of the subject, provide 10 relevant keywords, seperation by ','\"\n",
    "# text_prompt_string = \"Analyze the attention and engagement of the subject in the video. Classify the engagement level into one of the following categories: Highly-Engaged, Engaged, Barely-Engaged, Not-Engaged. Provide a brief explanation for the classification and 10 relevant keywords separated by semicolons.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96063b5e-1732-47fd-aecf-b8bcf799d97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Attention: Rarely\n",
      "2. Distractions: Often\n",
      "3. Facial Expressions: Rarely\n",
      "4. Eye Movement: Rarely\n",
      "5. Body Language: Rarely\n",
      "6. Consistency: Inconsistent\n",
      "7. Head Movement: Rarely\n",
      "8. Body Movement: Rarely\n",
      "9. Signs of Boredom: Rarely\n",
      "10. Head Position: Mostly upright\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"video_path\": video,\n",
    "    \"text_prompt\": text_prompt_string\n",
    "}\n",
    "\n",
    "output = replicate.run(\n",
    "    \"nateraw/video-llava:26387f81b9417278a8578188a31cd763eb3a55ca0f3ec375bf69c713de3fb4e8\",\n",
    "    input=input\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983cdb0-2972-4cb8-b832-6148cea89025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
